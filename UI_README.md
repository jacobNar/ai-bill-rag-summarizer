# Congress Legislation RAG Chat UI

A production-ready web interface for the Congressional bill RAG (Retrieval-Augmented Generation) chatbot, built with React, TypeScript, and FastAPI.

## ğŸš€ Live Demo
- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

## ğŸ—ï¸ Architecture

```
â”œâ”€â”€ frontend/                 # React/TypeScript UI
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # Reusable UI components
â”‚   â”‚   â”‚   â”œâ”€â”€ atoms/       # Basic components (Button, Input)
â”‚   â”‚   â”‚   â”œâ”€â”€ molecules/   # Composed components (BillCard)
â”‚   â”‚   â”‚   â”œâ”€â”€ organisms/   # Complex components (ChatInterface)
â”‚   â”‚   â”‚   â””â”€â”€ layout/      # Layout components (Header)
â”‚   â”‚   â”œâ”€â”€ pages/           # Page components
â”‚   â”‚   â”œâ”€â”€ store/           # Zustand state management
â”‚   â”‚   â”œâ”€â”€ services/        # API clients
â”‚   â”‚   â””â”€â”€ styles/          # Design tokens & global styles
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ backend/                 # FastAPI Python backend
â”‚   â”œâ”€â”€ main.py             # FastAPI server with RAG integration
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ start.sh           # Backend startup script
â””â”€â”€ bill-summarizer.py      # Original RAG implementation
```

## ğŸš€ Quick Start

### Prerequisites

1. **Ollama** running locally with required models:
   ```bash
   # Install Ollama (https://ollama.ai)
   ollama serve
   
   # Install required models (or use your existing models)
   ollama pull llama3.1:8b  # or llama3.2 if available
   ollama pull mxbai-embed-large
   ```

2. **Node.js** 18+ and **Python** 3.9+

### 1. Start the Backend

```bash
# Install Python dependencies
cd backend
pip3 install -r requirements.txt

# Start the FastAPI server
python3 main.py
# Server runs on http://localhost:8000
# API documentation available at http://localhost:8000/docs
```

### 2. Start the Frontend

```bash
# Install Node dependencies
cd frontend
npm install

# Start the development server
npm run dev
# App runs on http://localhost:5173
```

### 3. Access the Application

- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

## ğŸ¨ Design System

The UI implements a comprehensive design system based on the included style guide:

- **Colors**: Federal Navy, Congressional Red, clean neutrals
- **Typography**: Inter font with semantic sizing scale
- **Spacing**: 8-point grid system
- **Components**: Fully accessible with WCAG 2.1 AA compliance
- **Responsive**: Mobile-first design with 4 breakpoints

### Key Features

- âœ… **Accessible**: Full keyboard navigation, screen reader support
- âœ… **Responsive**: Works on desktop, tablet, and mobile
- âœ… **Real-time**: Streaming chat with WebSocket support
- âœ… **Type-safe**: Full TypeScript coverage
- âœ… **Performance**: Optimized with code splitting and lazy loading

## ğŸ”§ Technology Stack

### Frontend
- **React 18** - UI framework
- **TypeScript 5** - Type safety
- **Vite 7** - Build tool and dev server
- **Styled Components** - CSS-in-JS styling
- **Zustand** - State management
- **Axios** - HTTP client
- **React Router 6** - Client-side routing

### Backend
- **FastAPI** - Modern Python web framework
- **Ollama** - Local LLM inference (llama3.1:8b)
- **ChromaDB** - Vector database
- **LangChain** - RAG pipeline
- **Uvicorn** - ASGI server
- **Transformers** - Document re-ranking

## ğŸ“± Features

### Chat Interface
- Real-time streaming responses
- Message history with session persistence
- Source document citations
- Keyboard shortcuts (Enter to send, Shift+Enter for new line)
- Loading states and error handling

### Bill Search & Browse
- Full-text search across bill content
- Advanced filtering (chamber, status, date, sponsor)
- Responsive card-based layout
- Infinite scroll pagination

### Accessibility
- Skip navigation links
- ARIA live regions for chat updates
- High contrast color schemes (4.5:1+ ratios)
- Full keyboard navigation
- Screen reader optimized

## ğŸ› ï¸ Development

### Project Scripts

**Frontend:**
```bash
npm run dev          # Start development server
npm run build        # Build for production
npm run preview      # Preview production build
npm run lint         # Lint code
npm run type-check   # TypeScript checking
```

**Backend:**
```bash
./start.sh           # Start with virtual environment
python main.py       # Direct start
uvicorn main:app --reload  # Development with auto-reload
```

### Environment Variables

Create `frontend/.env`:
```env
VITE_API_URL=http://localhost:8000/api/v1
VITE_WS_URL=ws://localhost:8000
```

### Testing

```bash
# Frontend tests (when added)
cd frontend
npm run test

# Backend tests (when added)
cd backend
pytest
```

## ğŸ“Š API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/v1/health` | Health check |
| GET | `/api/v1/bills` | Search/filter bills |
| GET | `/api/v1/bills/{id}` | Get specific bill |
| POST | `/api/v1/chat/message` | Send chat message |
| POST | `/api/v1/search` | Advanced search |
| WS | `/ws/{session_id}` | WebSocket chat |

## ğŸ”„ Data Flow

1. **User Input** â†’ Frontend React components
2. **API Calls** â†’ FastAPI backend via axios
3. **RAG Processing** â†’ Existing bill-summarizer.py integration
4. **Vector Search** â†’ ChromaDB similarity search
5. **LLM Generation** â†’ Ollama local inference
6. **Streaming Response** â†’ WebSocket â†’ React state updates
7. **UI Updates** â†’ Styled components with design tokens

## ğŸ“ˆ Performance

- **Bundle Size**: <200KB initial (gzipped)
- **First Load**: <2s LCP target
- **API Response**: <500ms for chat messages
- **Streaming**: 30+ tokens/second display rate

## ğŸ” Security

- CORS properly configured
- Input sanitization on all user inputs
- No sensitive data in localStorage
- XSS protection via styled-components
- Rate limiting on API endpoints

## ğŸ“± Browser Support

- Chrome 90+
- Firefox 88+
- Safari 14+
- Edge 90+

## ğŸš€ Deployment

### Frontend (Vercel/Netlify)
```bash
npm run build
# Deploy dist/ folder
```

### Backend (Docker)
```dockerfile
FROM python:3.11
COPY . /app
WORKDIR /app
RUN pip install -r backend/requirements.txt
CMD [\"python\", \"backend/main.py\"]
```

## ğŸ¤ Contributing

1. Follow the existing code style
2. Maintain design system consistency  
3. Add TypeScript types for new features
4. Test accessibility with screen readers
5. Update documentation for new components

## ğŸ“ Documentation

- **Style Guide**: `STYLE_GUIDE.md` - Complete design system
- **TRD**: `TRD.md` - Technical requirements
- **Claude Guide**: `CLAUDE.md` - Development context
- **Original README**: `README.md` - RAG system details

## ğŸ› Troubleshooting

### Common Issues

1. **Ollama not running**: Ensure `ollama serve` is active
2. **Models not found**: Run `ollama pull llama3.2 && ollama pull mxbai-embed-large`
3. **CORS errors**: Check API_URL in frontend/.env
4. **Build errors**: Clear node_modules and reinstall
5. **Python errors**: Activate virtual environment and install requirements

### Debug Commands
```bash
# Check Ollama status
ollama list

# Check API health
curl http://localhost:8000/api/v1/health

# Check frontend build
cd frontend && npm run build
```

---

**Built with â¤ï¸ for transparent democracy through accessible technology.**